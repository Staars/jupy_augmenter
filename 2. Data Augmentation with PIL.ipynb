{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Augmentation Techniques\n",
    "* Scaling\n",
    "* Translation\n",
    "* Rotation (at 90 degrees)\n",
    "* Rotation (at finer angles)\n",
    "* Flipping\n",
    "* Adding Salt and Pepper noise\n",
    "* Lighting condition\n",
    "* Perspective transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageEnhance, ImageOps, ImageFilter\n",
    "import glob\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change image size if needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling:\n",
    "Having differently scaled object of interest in the images is the most important aspect of image diversity. When your network is in hands of real users, the object in the image can be tiny or large. Also, sometimes, object can cover the entire image and yet will not be present totally in image (i.e cropped at edges of object). The code shows scaling of image centrally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Translation:\n",
    "We would like our network to recognize the object present in any part of the image. Also, the object can be present partially in the corner or edges of the image. For this reason, we shift the object to various parts of the image. This may also result in addition of a background noise. The code snippet shows translating the image at four sides retaining 80 percent of the base image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotation (at 90 degrees):\n",
    "The network has to recognize the object present in any orientation. Assuming the image is square, rotating the image at 90 degrees will not add any background noise in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Rotation (at finer angles):\n",
    "Depending upon the requirement, there maybe a necessity to orient the object at minute angles. However problem with this approach is, it will add background noise. If the background in image is of a fixed color (say white or black), the newly added background can blend with the image. However, if the newly added background color doesn’t blend, the network may consider it as to be a feature and learn unnecessary features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flipping:\n",
    "This scenario is more important for network to remove biasness of assuming certain features of the object is available in only a particular side. Consider the case shown in image example. You don’t want network to learn that tilt of banana happens only in right side as observed in the base image. Also notice that flipping produces different set of images from rotation at multiple of 90 degrees.My additional question is has anyone done some study on what is the maximum number of classes it gives good performance. Consider, data can be generated with good amount of diversity for each class and time of training is not a factor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding Salt and Pepper noise:\n",
    "Salt and Pepper noise refers to addition of white and black dots in the image. Though this may seem unnecessary, it is important to remember that a general user who is taking image to feed into your network may not be a professional photographer. His camera can produce blurry images with lots of white and black dots. This augmentation aides the above mentioned users.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lighting condition:\n",
    "This is a very important type of diversity needed in the image dataset not only for the network to learn properly the object of interest but also to simulate the practical scenario of images being taken by the user. The lighting condition of the images are varied by adding Gaussian noise in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perspective transform:\n",
    "In perspective transform, we try to project image from a different point of view. For this, the position of object should be known in advance. Merely calculating perspective transform without knowing the position of the object can lead to degradation of the dataset. Hence, this type of augmentation has to be performed selectively. The greatest advantage with this augmentation is that it can emphasize on parts of object in image which the network needs to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate and save augmented images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_noise(img, path ):   \n",
    "    idx = 0\n",
    "    # red, green, blue = img.split()\n",
    "    for loc in range(0,5):\n",
    "        for scale in range(30,60,5):\n",
    "            for y in range(img.height):\n",
    "                for x in range(img.width):\n",
    "                    gauss = np.random.normal(loc,scale)\n",
    "                    value = img.getpixel((x, y))\n",
    "                    image_red = (value[0] + int(gauss), value[1], value[2])\n",
    "                    img.putpixel((x, y), image_red)\n",
    "            \n",
    "            filename = \"img_gaussian_noise_{0}\".format(idx)\n",
    "            new_path = path.format(filename)\n",
    "            img.save(new_path)\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_blur(img, path ):   \n",
    "    idx = 0\n",
    "    for radius in range(1,5):\n",
    "            img = img.filter(ImageFilter.BoxBlur(radius))\n",
    "            filename = \"img_box blur_{0}\".format(idx)\n",
    "            new_path = path.format(filename)\n",
    "            img.save(new_path)\n",
    "            idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_center(pil_img, crop_width, crop_height):\n",
    "    img_width, img_height = pil_img.size\n",
    "    return pil_img.crop(((img_width - crop_width) // 2,\n",
    "                         (img_height - crop_height) // 2,\n",
    "                         (img_width + crop_width) // 2,\n",
    "                         (img_height + crop_height) // 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ScaleRotateTranslate(image, angle, center = None, new_center = None, scale = None,expand=False):\n",
    "    if center is None:\n",
    "        return image.rotate(angle)\n",
    "    angle = -angle/180.0*math.pi\n",
    "    nx,ny = x,y = center\n",
    "    sx=sy=1.0\n",
    "    if new_center:\n",
    "        (nx,ny) = new_center\n",
    "    if scale:\n",
    "        (sx,sy) = scale\n",
    "    cosine = math.cos(angle)\n",
    "    sine = math.sin(angle)\n",
    "    a = cosine/sx\n",
    "    b = sine/sx\n",
    "    c = x-nx*a-ny*b\n",
    "    d = -sine/sy\n",
    "    e = cosine/sy\n",
    "    f = y-nx*d-ny*e\n",
    "    return image.transform(image.size, Image.AFFINE, (a,b,c,d,e,f), resample=Image.BICUBIC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_image(img,path):\n",
    "    # scale = [0.97,0.96,0.95,0.94,0.93,0.92,0.91,0.90,0.89,0.88,0.87,0.86,0.85,0.84,0.80,0.75,0.70,0.65,0.60]\n",
    "    scale = [0.99,0.98,0.97,0.96,0.95]\n",
    "    for i in range(0, len(scale)):\n",
    "        new_length = int(IMAGE_SIZE/scale[i])\n",
    "        scaled_size = (new_length,new_length)\n",
    "        new_image = img.resize(scaled_size)\n",
    "        new_image = crop_center(new_image, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        # new_image = new_image.crop(((new_length - IMAGE_SIZE)/2 ,(new_length - IMAGE_SIZE)/2, IMAGE_SIZE,IMAGE_SIZE )) #(left, top, right, bottom)\n",
    "        new_image = new_image.resize((IMAGE_SIZE,IMAGE_SIZE))\n",
    "        filename = \"img_scale_{0}\".format(i)\n",
    "        new_path = path.format(filename)\n",
    "        new_image.save(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def widen_image(img,path):\n",
    "    scale = [0.97,0.96,0.95,0.94,0.93,0.92,0.91,0.90,0.89,0.88,0.87,0.86,0.85,0.84,0.80,0.75,0.70,0.65,0.60]\n",
    "    # scale = [0.99,0.98,0.97,0.96,0.95]\n",
    "    for i in range(0, len(scale)):\n",
    "        new_length = int(IMAGE_SIZE/scale[i])\n",
    "        scaled_size = (new_length,IMAGE_SIZE)\n",
    "        new_image = img.resize(scaled_size)\n",
    "        new_image = crop_center(new_image, IMAGE_SIZE, IMAGE_SIZE)\n",
    "        # new_image = new_image.crop(((new_length - IMAGE_SIZE)/2 ,(new_length - IMAGE_SIZE)/2, IMAGE_SIZE,IMAGE_SIZE )) #(left, top, right, bottom)\n",
    "        new_image = new_image.resize((IMAGE_SIZE,IMAGE_SIZE))\n",
    "        filename = \"img_widen_{0}\".format(i)\n",
    "        new_path = path.format(filename)\n",
    "        new_image.save(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrast_image(img,path):\n",
    "    factor = [0.90,0.80,0.70,0.60,0.50,0.40,0.30,0.20,0.10]\n",
    "    for i in range(0, len(factor)):\n",
    "        filter = ImageEnhance.Contrast(img)\n",
    "        new_image = filter.enhance(factor[i])\n",
    "        filename = \"img_contrast_\" + str(i)\n",
    "        new_path = path.format(filename)\n",
    "        new_image.save(new_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tranlate_image(folder, img):\n",
    "    translated_imgs = translate_images(img)\n",
    "    \n",
    "    for i in range(-4, 4):\n",
    "        filename = \"img_translate_{0}\".format(i)\n",
    "        filepath = new_img_name(folder, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shear(img,path):\n",
    "    for x in range(-10,10):\n",
    "        transform = (1,x/100,0,\n",
    "                     0,1,0)\n",
    "        new_image = image.transform(image.size, Image.AFFINE, transform, resample=Image.BICUBIC)\n",
    "        filename = \"img_shearx_\" + str(x)\n",
    "        new_path = path.format(filename)\n",
    "        new_image.save(new_path)\n",
    "    for y in range(-10,10):\n",
    "        transform = (1,0,0,\n",
    "                     y/100,1,0)\n",
    "        new_image = image.transform(image.size, Image.AFFINE, transform, resample=Image.BICUBIC)\n",
    "        filename = \"img_sheary_\" + str(y)\n",
    "        new_path = path.format(filename)\n",
    "        new_image.save(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rotate_general_image(img, path):\n",
    "    for degree in range(-10,10):\n",
    "        new_image = ScaleRotateTranslate(img,degree)\n",
    "        filename = \"img_rotate_{0}\".format(degree)\n",
    "        new_path = path.format(filename)\n",
    "        new_image.save(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert(img, path):\n",
    "    # try:\n",
    "    im_invert = ImageOps.invert(img)\n",
    "    # except:\n",
    "    #     return\n",
    "    filename = \"img_inverted_\"\n",
    "    new_path = path.format(filename)\n",
    "    im_invert.save(new_path)\n",
    "    # print(path, new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def exec_images(img, path):\n",
    "    # Reduce contrast 97% - 60%\n",
    "    contrast_image(img, path)\n",
    "    # Scale 97% - 60%\n",
    "    scaled_image(img, path)\n",
    "    # Widen 97% - 60%\n",
    "    widen_image(img, path)\n",
    "    # Box blur 1 -5\n",
    "    box_blur(img, path)\n",
    "    # # Tranlate the images\n",
    "    # tranlate_image(i, img)\n",
    "    # # Rotate the image -10 to 10 degress\n",
    "    rotate_general_image(img, path)\n",
    "    # Shear the image\n",
    "    shear(img, path)\n",
    "    # # # Flip the image\n",
    "    # # flipped_image(i, img)\n",
    "    # # Add noise in pixels\n",
    "    # salt_pepper(i, img)\n",
    "    # Add gaussian noise in pixels\n",
    "    gaussian_noise(img, path)\n",
    "    # # Lighting condition\n",
    "    # lighting(i, img)\n",
    "    # print(\"Processing done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_folders = glob.glob(\"augmented/*/*.*\")\n",
    "img_paths = ['{}'.format(file) for file in target_folders]\n",
    "# filename = 'img_0.png'\n",
    "# path = ''\n",
    "\n",
    "for img_path in img_paths:\n",
    "        path = img_path.split(\".\")[-2] + \"_{0}.\" + img_path.split(\".\")[-1] #  \n",
    "        # print(path)\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        newsize = (IMAGE_SIZE, IMAGE_SIZE)\n",
    "        image = image.resize(newsize)\n",
    "        plt.imshow(image)\n",
    "        exec_images(image, path)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create inverted images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirList = glob.glob(\"augmented/*/*.*\")\n",
    "img_paths = ['{}'.format(file) for file in dirList]\n",
    "\n",
    "for img_path in img_paths:\n",
    "        path = img_path.split(\".\")[-2] + \"_{0}.\" + img_path.split(\".\")[-1]\n",
    "        image = Image.open(img_path)\n",
    "        invert(image, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirList = glob.glob(\"augmented/*/*.*\")\n",
    "img_paths = ['{}'.format(file) for file in dirList]\n",
    "\n",
    "for img_path in img_paths:\n",
    "        path = img_path.split(\".\")[-2] + \"_{0}.\" + img_path.split(\".\")[-1]\n",
    "        artefact_image = Image.open(img_path).convert('RGB')\n",
    "        JPG_PATH = img_path.split(\".\")\n",
    "        JPG_PATH.pop()\n",
    "        JPG_PATH = \"/\".join(JPG_PATH) + \".jpg\"\n",
    "        # print(PATH+JPG_PATH)\n",
    "        artefact_image.save(JPG_PATH, quality=5) # we want compression artefacts"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
